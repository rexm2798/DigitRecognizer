{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d013fe57",
   "metadata": {},
   "source": [
    "# Handwritten Digit Recognition with Neural Network (from Scratch)\n",
    "This notebook builds a simple neural network using only NumPy, Pandas to classify digits from the MNIST dataset.\n",
    "We’ll walk through data loading, preprocessing, model creation, training, and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872957ed",
   "metadata": {},
   "source": [
    "## 1. Importing Required Libraries\n",
    "We start by importing NumPy for numerical operations, pandas for data handling, and matplotlib for visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92be8522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeb2ac7",
   "metadata": {},
   "source": [
    "## 2. Loading the Dataset\n",
    "We load the `train.csv` file which contains labeled images of handwritten digits. Each row represents one image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3504e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with shape: (42000, 785)\n"
     ]
    }
   ],
   "source": [
    "# Load the MNIST training dataset\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Display the shape of the dataset\n",
    "print(f\"Loaded dataset with shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6b951c",
   "metadata": {},
   "source": [
    "## 3. Exploring the Dataset\n",
    "We convert the dataset to a NumPy array and print its dimensions to understand how many examples and features we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fa03bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 42000 examples with 785 features (including the label).\n"
     ]
    }
   ],
   "source": [
    "# Convert DataFrame to NumPy array and get dataset shape\n",
    "data = np.array(data)\n",
    "m, n = data.shape\n",
    "print(f\"Dataset contains {m} examples with {n} features (including the label).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dd1010",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing\n",
    "\n",
    "Before training the neural network, we need to prepare the dataset:\n",
    "\n",
    "1. **Shuffle** the data to remove any ordering bias\n",
    "2. **Normalize** the pixel values from the range [0, 255] to [0, 1]\n",
    "3. **Split** the data into a training set and a dev set\n",
    "4. **Transpose** the input matrix so that each column represents one training example\n",
    "\n",
    "---\n",
    "\n",
    "#### Why Transpose?\n",
    "\n",
    "Neural networks process data as:\n",
    "\n",
    "$$\n",
    "X = [x^{(1)}, x^{(2)}, ..., x^{(m)}] \\in \\mathbb{R}^{n \\times m}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- \\( n \\) is the number of features (in our case, 784 pixels per image)\n",
    "- \\( m \\) is the number of training examples\n",
    "\n",
    "This column-wise format allows vectorized matrix operations like:\n",
    "\n",
    "$$\n",
    "Z = W X + b\n",
    "$$\n",
    "\n",
    "to apply the same weights across all examples efficiently.  \n",
    "So, we reshape our dataset to match this expected structure before feeding it into the network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a318804d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataset to avoid any ordering bias\n",
    "np.random.shuffle(data)\n",
    "\n",
    "# Split the dataset into training and dev sets\n",
    "# Transpose so that each column represents one example\n",
    "data_dev = data[1:1000].T\n",
    "X_dev = data_dev[1:] / 255.0  # Normalize pixel values\n",
    "Y_dev = data_dev[0]\n",
    "\n",
    "data_train = data[1000:].T\n",
    "X_train = data_train[1:] / 255.0  # Normalize pixel values\n",
    "Y_train = data_train[0]\n",
    "\n",
    "# Get the number of training examples\n",
    "_, m_train = X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cf788c",
   "metadata": {},
   "source": [
    "## 5. Neural Network Implementation\n",
    "\n",
    "### 5.1 Neural Network Architecture Overview\n",
    "We build a simple feedforward neural network with the following structure:\n",
    "- **Input layer**: 784 units (one for each pixel in a 28×28 grayscale image)\n",
    "- **Hidden layer**: 10 neurons with ReLU activation\n",
    "- **Output layer**: 10 neurons with softmax activation, one for each digit class (0–9)\n",
    "---\n",
    "\n",
    "### 5.2 Initializing Parameters\n",
    "- We randomly initialize the weights and biases for both layers.\n",
    "- This helps break symmetry and allows the network to begin learning.\n",
    "---\n",
    "\n",
    "### 5.3 Activation Functions\n",
    "We define the activation functions used in the network:\n",
    "- **ReLU (Rectified Linear Unit)** for the hidden layer\n",
    "- **Softmax** for the output layer to convert scores into probabilities\n",
    "---\n",
    "\n",
    "### 5.4 Forward Propagation\n",
    "\n",
    "In forward propagation, we compute activations layer by layer using weights, biases, and activation functions.\n",
    "\n",
    "Let:\n",
    "\n",
    "- $X \\in \\mathbb{R}^{784 \\times m}$: input matrix (each column is an image)\n",
    "- $W^{[1]} \\in \\mathbb{R}^{10 \\times 784}$, $b^{[1]} \\in \\mathbb{R}^{10 \\times 1}$: weights and bias of the first (hidden) layer\n",
    "- $W^{[2]} \\in \\mathbb{R}^{10 \\times 10}$, $b^{[2]} \\in \\mathbb{R}^{10 \\times 1}$: weights and bias of the output layer\n",
    "- $m$: number of training examples\n",
    "\n",
    "#### Step-by-step Computation:\n",
    "\n",
    "**Hidden layer**:\n",
    "\n",
    "$$\n",
    "Z^{[1]} = W^{[1]} X + b^{[1]}\n",
    "$$\n",
    "\n",
    "$$\n",
    "A^{[1]} = \\text{ReLU}(Z^{[1]}) = \\max(0, Z^{[1]})\n",
    "$$\n",
    "\n",
    "**Output layer**:\n",
    "\n",
    "$$\n",
    "Z^{[2]} = W^{[2]} A^{[1]} + b^{[2]}\n",
    "$$\n",
    "\n",
    "$$\n",
    "A^{[2]} = \\text{softmax}(Z^{[2]}) = \\frac{e^{Z^{[2]}}}{\\sum e^{Z^{[2]}}}\n",
    "$$\n",
    "\n",
    "Softmax is applied column-wise to ensure each column of \\( A^{[2]} \\) sums to 1.\n",
    "\n",
    "#### Example Output:\n",
    "\n",
    "If the image is a \"3\", then:\n",
    "\n",
    "$$\n",
    "A^{[2]} = [0.01, 0.02, 0.01, \\mathbf{0.94}, 0.01, \\dots]\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 5.5 One-Hot Encoding\n",
    "\n",
    "In a multi-class classification problem like digit recognition (0–9), we need to compare the predicted probabilities with the true labels.  \n",
    "Since labels are scalar integers (e.g., 3, 7), we convert them into **one-hot encoded vectors** for mathematical compatibility during loss calculation and backpropagation.\n",
    "\n",
    "#### Definition:\n",
    "\n",
    "If a label $y = 3$, the corresponding one-hot encoded vector $\\mathbf{y} \\in \\mathbb{R}^{10 \\times 1}$ is:\n",
    "\n",
    "$$\n",
    "\\mathbf{y} = \n",
    "\\begin{bmatrix}\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "1 \\\\\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "So in general:\n",
    "\n",
    "- If $Y \\in \\mathbb{R}^{1 \\times m}$ contains labels (digits 0–9),\n",
    "- Then one-hot encoding creates $Y_{\\text{one-hot}} \\in \\mathbb{R}^{10 \\times m}$, where each column is a one-hot vector.\n",
    "\n",
    "#### Why it's important:\n",
    "\n",
    "During backpropagation, we subtract the one-hot encoded labels from the predicted softmax probabilities:\n",
    "\n",
    "$$\n",
    "\\delta^{[2]} = A^{[2]} - Y_{\\text{one-hot}}\n",
    "$$\n",
    "\n",
    "This allows us to compute the **cross-entropy gradient** effectively.\n",
    "\n",
    "---\n",
    "\n",
    "### 5.6 Backward Propagation\n",
    "\n",
    "Once we compute predictions using forward propagation, we calculate how far off the predictions are from the actual labels. Backward propagation helps us compute the **gradients** of the loss with respect to each parameter so we can update them and reduce the error.\n",
    "\n",
    "#### Loss Function\n",
    "\n",
    "We use **cross-entropy loss** for multi-class classification:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = -\\frac{1}{m} \\sum_{i=1}^{m} \\sum_{j=1}^{10} Y_j^{(i)} \\log\\left(A_j^{[2](i)}\\right)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $Y^{(i)}$ is the one-hot encoded true label for the $i$-th training example\n",
    "- $A^{[2](i)}$ is the predicted softmax output for the $i$-th example\n",
    "- $m$ is the total number of examples\n",
    "\n",
    "#### Gradients for Output Layer\n",
    "\n",
    "Let:\n",
    "- $A^{[2]} \\in \\mathbb{R}^{10 \\times m}$: output of the softmax layer\n",
    "- $Y \\in \\mathbb{R}^{10 \\times m}$: one-hot encoded labels\n",
    "\n",
    "Then the error at the output is:\n",
    "\n",
    "$$\n",
    "\\delta^{[2]} = A^{[2]} - Y\n",
    "$$\n",
    "\n",
    "Gradients for weights and biases in the output layer:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial W^{[2]}} = \\frac{1}{m} \\delta^{[2]} (A^{[1]})^T\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial b^{[2]}} = \\frac{1}{m} \\sum_{i=1}^{m} \\delta^{[2](i)}\n",
    "$$\n",
    "\n",
    "#### Gradients for Hidden Layer\n",
    "\n",
    "We propagate the error back to the hidden layer:\n",
    "\n",
    "$$\n",
    "\\delta^{[1]} = (W^{[2]})^T \\delta^{[2]} \\circ \\mathbb{1}(Z^{[1]} > 0)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\circ$ denotes element-wise multiplication (Hadamard product)\n",
    "- $\\mathbb{1}(Z^{[1]} > 0)$ is the derivative of ReLU (i.e., 1 where $Z^{[1]} > 0$, else 0)\n",
    "\n",
    "Gradients for weights and biases in the hidden layer:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial W^{[1]}} = \\frac{1}{m} \\delta^{[1]} X^T\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial b^{[1]}} = \\frac{1}{m} \\sum_{i=1}^{m} \\delta^{[1](i)}\n",
    "$$\n",
    "\n",
    "Backward propagation allows the network to understand how each parameter contributed to the error and adjust accordingly using gradient descent. This is the core of how the network \"learns\".\n",
    "\n",
    "---\n",
    "\n",
    "### 5.7 Updating Parameters\n",
    "\n",
    "We update the weights and biases using gradient descent to minimize the loss.\n",
    "\n",
    "Let:\n",
    "- $\\alpha$ be the learning rate\n",
    "- $\\frac{\\partial \\mathcal{L}}{\\partial W^{[l]}}$, $\\frac{\\partial \\mathcal{L}}{\\partial b^{[l]}}$ be the gradients for layer $l$\n",
    "\n",
    "Update rules:\n",
    "\n",
    "$$\n",
    "W^{[l]} := W^{[l]} - \\alpha \\cdot \\frac{\\partial \\mathcal{L}}{\\partial W^{[l]}}, \\quad\n",
    "b^{[l]} := b^{[l]} - \\alpha \\cdot \\frac{\\partial \\mathcal{L}}{\\partial b^{[l]}}\n",
    "$$\n",
    "\n",
    "Applied to both layers ($l = 1, 2$). The learning rate $\\alpha$ controls the step size.\n",
    "\n",
    "---\n",
    "\n",
    "### 5.8 Making Predictions and Evaluating Accuracy\n",
    "\n",
    "To get the predicted label, we take the index of the highest value from the softmax output $A^{[2]}$:\n",
    "\n",
    "$$\n",
    "\\text{predictions} = \\arg\\max(A^{[2]}, \\text{ axis}=0)\n",
    "$$\n",
    "\n",
    "Accuracy is computed by comparing these predictions to the true labels $Y$:\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{1}{m} \\sum_{i=1}^{m} \\mathbb{1}(\\text{prediction}^{(i)} = Y^{(i)})\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $A^{[2]}$ is the output from the softmax layer\n",
    "- $\\text{prediction}^{(i)}$ is the predicted class for the $i$-th example\n",
    "- $Y^{(i)}$ is the true label\n",
    "- $\\mathbb{1}(\\cdot)$ is an indicator function that returns 1 if the condition is true, and 0 otherwise\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8eb1146f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size=784, hidden_size=10, output_size=10):\n",
    "        self.W1 = np.random.rand(hidden_size, input_size) - 0.5\n",
    "        self.b1 = np.random.rand(hidden_size, 1) - 0.5\n",
    "        self.W2 = np.random.rand(output_size, hidden_size) - 0.5\n",
    "        self.b2 = np.random.rand(output_size, 1) - 0.5\n",
    "\n",
    "    def ReLU(self, Z):\n",
    "        return np.maximum(0, Z)\n",
    "\n",
    "    def ReLU_deriv(self, Z):\n",
    "        return Z > 0\n",
    "\n",
    "    def softmax(self, Z):\n",
    "        Z_shifted = Z - np.max(Z, axis=0, keepdims=True)\n",
    "        expZ = np.exp(Z_shifted)\n",
    "        return expZ / np.sum(expZ, axis=0, keepdims=True)\n",
    "\n",
    "    def forward(self, X):\n",
    "        Z1 = self.W1 @ X + self.b1\n",
    "        A1 = self.ReLU(Z1)\n",
    "        Z2 = self.W2 @ A1 + self.b2\n",
    "        A2 = self.softmax(Z2)\n",
    "        return Z1, A1, Z2, A2\n",
    "\n",
    "    def one_hot(self, Y):\n",
    "        one_hot_Y = np.zeros((Y.max()+1, Y.size))\n",
    "        one_hot_Y[Y, np.arange(Y.size)] = 1\n",
    "        return one_hot_Y\n",
    "\n",
    "    def backward(self, X, Y, Z1, A1, A2):\n",
    "        m = X.shape[1]\n",
    "        one_hot_Y = self.one_hot(Y)\n",
    "        dZ2 = A2 - one_hot_Y\n",
    "        dW2 = 1/m * dZ2 @ A1.T\n",
    "        db2 = 1/m * np.sum(dZ2, axis=1, keepdims=True)\n",
    "        dZ1 = (self.W2.T @ dZ2) * self.ReLU_deriv(Z1)\n",
    "        dW1 = 1/m * dZ1 @ X.T\n",
    "        db1 = 1/m * np.sum(dZ1, axis=1, keepdims=True)\n",
    "        return dW1, db1, dW2, db2\n",
    "\n",
    "    def update(self, dW1, db1, dW2, db2, alpha):\n",
    "        self.W1 -= alpha * dW1\n",
    "        self.b1 -= alpha * db1\n",
    "        self.W2 -= alpha * dW2\n",
    "        self.b2 -= alpha * db2\n",
    "\n",
    "    def train(self, X, Y, iterations, alpha):\n",
    "        for i in range(iterations):\n",
    "            Z1, A1, Z2, A2 = self.forward(X)\n",
    "            dW1, db1, dW2, db2 = self.backward(X, Y, Z1, A1, A2)\n",
    "            self.update(dW1, db1, dW2, db2, alpha)\n",
    "            if i % 10 == 0:\n",
    "                preds = self.predict(X)\n",
    "                acc = self.accuracy(preds, Y)\n",
    "                print(f\"Iteration {i} - Accuracy: {acc:.4f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        _, _, _, A2 = self.forward(X)\n",
    "        return np.argmax(A2, axis=0)\n",
    "\n",
    "    def accuracy(self, preds, Y):\n",
    "        return np.mean(preds == Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c09048f",
   "metadata": {},
   "source": [
    "## 6. Training the Model\n",
    "\n",
    "We now train the neural network using the training set.\n",
    "\n",
    "In each iteration, the model:\n",
    "- Performs forward propagation to compute predictions\n",
    "- Uses backward propagation to calculate gradients\n",
    "- Updates weights and biases using gradient descent\n",
    "\n",
    "We repeat this process for a fixed number of iterations (e.g., 500).  \n",
    "This allows the model to gradually minimize the loss and improve accuracy.\n",
    "\n",
    "The **learning rate**, denoted by alpha $\\alpha$, controls how big each parameter update step is:\n",
    "- A small $\\alpha$ (e.g., 0.01) leads to slower but stable learning\n",
    "- A large $\\alpha$ (e.g., 0.5) may speed up training but can overshoot or diverge\n",
    "\n",
    "In our case, we use:\n",
    "- Iterations = 500\n",
    "- alpha = 0.10 (Change the weights and biases by 10% of the calculated gradient every iteration.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f21079f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 - Accuracy: 0.0541\n",
      "Iteration 10 - Accuracy: 0.1139\n",
      "Iteration 20 - Accuracy: 0.1526\n",
      "Iteration 30 - Accuracy: 0.1922\n",
      "Iteration 40 - Accuracy: 0.2522\n",
      "Iteration 50 - Accuracy: 0.2791\n",
      "Iteration 60 - Accuracy: 0.3049\n",
      "Iteration 70 - Accuracy: 0.3337\n",
      "Iteration 80 - Accuracy: 0.3677\n",
      "Iteration 90 - Accuracy: 0.4087\n",
      "Iteration 100 - Accuracy: 0.4556\n",
      "Iteration 110 - Accuracy: 0.5070\n",
      "Iteration 120 - Accuracy: 0.5447\n",
      "Iteration 130 - Accuracy: 0.5719\n",
      "Iteration 140 - Accuracy: 0.5915\n",
      "Iteration 150 - Accuracy: 0.6097\n",
      "Iteration 160 - Accuracy: 0.6261\n",
      "Iteration 170 - Accuracy: 0.6409\n",
      "Iteration 180 - Accuracy: 0.6551\n",
      "Iteration 190 - Accuracy: 0.6689\n",
      "Iteration 200 - Accuracy: 0.6815\n",
      "Iteration 210 - Accuracy: 0.6927\n",
      "Iteration 220 - Accuracy: 0.7040\n",
      "Iteration 230 - Accuracy: 0.7156\n",
      "Iteration 240 - Accuracy: 0.7250\n",
      "Iteration 250 - Accuracy: 0.7348\n",
      "Iteration 260 - Accuracy: 0.7437\n",
      "Iteration 270 - Accuracy: 0.7524\n",
      "Iteration 280 - Accuracy: 0.7606\n",
      "Iteration 290 - Accuracy: 0.7680\n",
      "Iteration 300 - Accuracy: 0.7747\n",
      "Iteration 310 - Accuracy: 0.7822\n",
      "Iteration 320 - Accuracy: 0.7884\n",
      "Iteration 330 - Accuracy: 0.7935\n",
      "Iteration 340 - Accuracy: 0.7984\n",
      "Iteration 350 - Accuracy: 0.8030\n",
      "Iteration 360 - Accuracy: 0.8074\n",
      "Iteration 370 - Accuracy: 0.8118\n",
      "Iteration 380 - Accuracy: 0.8156\n",
      "Iteration 390 - Accuracy: 0.8192\n",
      "Iteration 400 - Accuracy: 0.8218\n",
      "Iteration 410 - Accuracy: 0.8250\n",
      "Iteration 420 - Accuracy: 0.8281\n",
      "Iteration 430 - Accuracy: 0.8304\n",
      "Iteration 440 - Accuracy: 0.8327\n",
      "Iteration 450 - Accuracy: 0.8347\n",
      "Iteration 460 - Accuracy: 0.8370\n",
      "Iteration 470 - Accuracy: 0.8387\n",
      "Iteration 480 - Accuracy: 0.8404\n",
      "Iteration 490 - Accuracy: 0.8422\n"
     ]
    }
   ],
   "source": [
    "# Create the neural network instance and begin training\n",
    "nn = NeuralNetwork()\n",
    "nn.train(X_train, Y_train, iterations=500, alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1c7995",
   "metadata": {},
   "source": [
    "### 7. Making Predictions and Visualizing Results\n",
    "\n",
    "After training the model, we can test its performance on individual examples.\n",
    "\n",
    "- The `predict()` method in our class uses forward propagation to compute the output and selects the digit with the highest probability.\n",
    "- We define a helper function `test_prediction()` to:\n",
    "  - Run prediction on a single example (by index)\n",
    "  - Display the predicted digit and actual label\n",
    "  - Show the corresponding image (28×28 grayscale)\n",
    "\n",
    "This helps us visually inspect whether the model is correctly identifying handwritten digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96ed7152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make predictions using the trained model (for any dataset)\n",
    "def make_predictions(model, X):\n",
    "    return model.predict(X)\n",
    "\n",
    "# Function to test a single example and show the image with prediction\n",
    "def test_prediction(index, model, X_data, Y_data):\n",
    "    \"\"\"\n",
    "    Displays the image at the given index and compares the model's prediction to the actual label.\n",
    "    \"\"\"\n",
    "    current_image = X_data[:, index, None]  # shape (784, 1)\n",
    "    prediction = make_predictions(model, current_image)\n",
    "    label = Y_data[index]\n",
    "\n",
    "    # print(f\"Prediction: {prediction[0]}\")\n",
    "    # print(f\"Actual Label: {label}\")\n",
    "\n",
    "    # Visualize the image\n",
    "    image_2d = current_image.reshape((28, 28)) * 255\n",
    "    plt.gray()\n",
    "    plt.imshow(image_2d, interpolation='nearest')\n",
    "    plt.title(f\"Predicted: {prediction[0]}, Actual: {label}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5a9c4cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAEw9JREFUeJzt3QlsZWX5wOGvMCAICAooy8ywRSGyGEGNHQ3gAggYN8aOYNxARUVgpiDBFXAhGqGFgAuECCqIdtxA4oqisnQU0WhQMS7ozIgRUNxAWc8/75d/X9pOZ+beS3u78DxJ7UznnHvPPaXnd893vh57mqZpCgCUUjaY7g0AYOYQBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBdZr5513Lq9//evz79///vdLT09P/TxTt5FH5sADD6wfPPqIwgx3ySWX1APwyMcmm2xSnvKUp5S3v/3t5a9//WuZTb7+9a+X008/vcxEf/nLX8qb3/zmsssuu5RNN9207LbbbqW/v7/87W9/e8SP/etf/zq/d//4xz86fpwzzzyzfPWrXy2zwT//+c9yyimnlCc/+cl1f+60007lmGOOKStXrpzuTWM95q1vAWaG97///fWA9b///a9cd9115ROf+EQ9yN58883lsY99bFe3Zf/99y///e9/y8Ybb9zWerG9H/vYx2ZcGP7zn/+U3t7ecvfdd5e3ve1tZcGCBeXnP/95Of/888s111xTbrrpprLBBp2/f7r00kvLdtttV+66667yxS9+sbzxjW/sOAqLFy8uL3vZy8pM9tBDD5WDDjqo/OpXv6r7M97E/O53vysf//jHy7e+9a0ayS222GK6N5O1EIVZ4tBDDy3PeMYz6p/joLL11luXgYGBcsUVV5QjjzxywnXiILfZZptN+rbEATLe9c4VV155ZfnTn/5UrrrqqnL44Yfn15/whCfUGEcgnv70p3f02HG/yc997nPlqKOOKrfeemu57LLLOo7CbLFixYpy44031qged9xx+fXdd9+9HH300eXqq68uL3/5y6d1G1k7w0ez1POf//z6OQ40IcbTN9988/L73/++HHbYYfWd2Ktf/ep853bOOeeUPffcsx7Mn/SkJ5Vjjz22vnMdfwD74Ac/WObPn1/PPp73vOeVX/7yl2s899quKfzoRz+qz/34xz++xmifffYp5557bm5fnCWE0cNhIyZ7G0Psi/hYn3/961/1czznaNtvv339HMMfnbr++uvLH//4x/KqV72qfvzwhz8sq1evXmO5eP2xr/bee+/6+rfddtvyohe9qPzkJz+p/x77KiL/6U9/OvfdyDWU+BzXVMaLM7LR+zhcfPHF9b+dJz7xieUxj3lMeepTn1rPOlsRQz+33HLLtO5Ppp4zhVlq5GAXZwwjHnjggXLIIYeU5z73ueWss87KYaU4uMa1iTe84Q3lhBNOqCGJd3E/+9nP6kFro402qsu9733vqwfcOLDHx09/+tNy8MEHl/vuu2+92/Od73ynvPjFL64/+CeeeGIdLolhgnj3HX+Pbbjtttvqcp/97GfXWH8qtvEFL3hB/RwH5fUNh8XZT2zn2WefXYPzi1/8onzoQx+qQzV77LFH6VScGcT1iWc+85llr732qt+Tyy+/vLzjHe8Ys1yMt8frjzPCOJOI7+W1115b33XHGWLss/j6s571rHrtI8TjtisCEOF9yUteUubNm1e+9rWv1SGeiNLod/UTee1rX1t+8IMf1DCvS2xvvCl473vfW8+24gwhho/iGkPshxe+8IVtbzddFP9/CsxcF198cfwENldffXVzxx13NKtWrWo+//nPN1tvvXWz6aabNqtXr67Lve51r6vLnXrqqWPWv/baa+vXL7vssjFf/+Y3vznm67fffnuz8cYbN4cffnjz0EMP5XLvete76nLx+COuueaa+rX4HB544IFml112aXbaaafmrrvuGvM8ox/ruOOOq+uNNxXbGGJ74qMVF110UbPVVlvVxxn5iMe7//77m07dd9999fv07ne/O7921FFHNU972tPGLPe9732vPt8JJ5ywxmOMfp2bbbbZGq8xxNcmep2nnXbaGvv7nnvuWWO5Qw45pNl1113HfO2AAw6oH+O/1uoh46qrrmq23377Mfsznuff//53S+szfQwfzRLx7iqGFOIiaAxDxFDRV77ylbLjjjuOWe6tb33rmL8vX768bLnllvXC35133pkf++23X32MuJAaYpw33m0ff/zxY4Ycli5dut5ti3fz8c4+lt1qq63G/Nv44YuJTNU2xhnC+s4SRsR+jHfhMYQV+zVmHsW7/FNPPbV06hvf+EadvTT6mk/8Oa5RjB7y+tKXvlRfz2mnnbbGY7Sy/9oxeugmZgjFfj7ggAPKH/7wh/r3dYnhwlb/P7niv9W4DhNnWzFjKoay4swnzgSZ2QwfzRIxHh+zOOKUP8Zq45R8/IyY+LcY+hjtt7/9bf1hjzHkidx+++31c1xoDTGFcPwPd1wjaGUoK4ZHOtGNbVyXGJ6Koa+RoZoQw0aPe9zjyhlnnFEvjsbYeyezjmLGWIzdx/DJyJBPDCFFcGI20cj+22GHHepQy1SL1xrxGR4eLvfcc8+Yf4vvQcT5kYrAxLWez3zmM+WII46oX3vpS1+av0sSsYxhMmYmUZgl4l3syAFrbeLgMz4UMVYcB9s4CE0kDqjTbbq38YILLqihHb9/Y9w93uHecMMNbUchLrbGeH1MIR4fsRAzkuJd9GScCaztMR588MExf4/4xHWWuEYSM9firDOmFcdU4cHBwfp9mAxxbSRed4R2/P4cCZMozFyiMMfFO9MYdnnOc56zzlkf8ctFI+/ad9111/z6HXfcscYMoImeI8TvTKzrIuLaDl7d2MZ1iV8CHH8ADffff3/9HBd92/XlL3+5Hhjjwu4222wz5t9+85vflPe85z314BiTAuL1x/z9v//97+s8W1jb/ouzpIl+KW7kzGpEROree++tU3AXLlyYXx8ZnpsssT9jmGn8Pn0k+5PucU1hjuvr66s/nB/4wAfW+Lf44Rw5mMTBPGb4nHfeeWPGjWOMfX323XffOkwSy44/OI1+rJHfmRi/zFRtY6tTUmNYLg5k46fYxiyh0MnvKMTQUYTrLW95S/2Fs9EfJ598cr1WMnJmFEMs8XpiqGq88ftvooN/RCWGfmLG1Ojf0I5rI6NtuOGGazxmrBfTVCdzSmrsz3iOoaGhSdufdNE0XuSmjdlHN9544zqXixkoMTtlIscee2x9jEMPPbQZHBxszj///ObEE09sdthhh2b58uW53Dvf+c663GGHHVaXOeaYY+oy22yzzTpnH43MFNpoo43qLJjTTz+9ueCCC5ply5Y1Bx98cC4zNDRU13vNa17TXHrppc3ll18+ZdvYzuyjW265pe67zTffvD7+Jz/5yebII4+sz3PQQQdN+P2Iz2vz5z//udlggw2apUuXrnWZI444os5MihlKIfbJyOs/99xz6z54xSte0Zx33nm5Trzm2M6zzz677rsVK1bUr99555316zGD6JxzzmnOPPPMZsGCBc2+++47ZrZQvM6YvbX33nvXfffhD3+42W233epsqFju1ltvnZTZR7E92223XX2umFEV/y3E93fDDTds9txzz+bee+9d72MwfUThURCFcOGFFzb77bdfnca6xRZb1APDKaec0tx22225zIMPPticccYZdSphLHfggQc2N998cz2wri8K4brrrqsH0Xj82JZ99tlnzEEtpq4ef/zxzbbbbtv09PSscYCZzG1sd0pqHDAXL15cD6YjcTv55JObu+++e8xy8XpiuyOCaxMH7Vjmu9/97lqXueSSS+oyV1xxRe6bj370o80ee+xRD6axjyIQN91005ht3H///evrHj8F99vf/naz11571XV33333Gt2JpqReeeWV9fuyySabNDvvvHPzkY98pPnUpz41qVEIMVX66KOPrlOVY5vi+/WmN72pTqtmZuuJ/+nmmQnMZjHUFdNcf/zjH0/3psCUcKEZWhTvn+K6Q1wvgLnKmQIAyewjAJIoAJBEAYAkCgC0P/tosu/WCEB3tTKvyJkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGANO/hP/JotWDBgrbXWbx4cdvr9Pb2lk7Mnz+/a8/VroGBgbbXOemkk6ZkW2AyOFMAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEByQ7w5dJO6sHTp0rbX6e/v7+i56Pz7NJP19fV15XmGhoa68jy0x5kCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQepqmaUoLenp6WlmMSdLit2XaDA8Pt73OkiVLOnquHXfcse11VqxY0ZW7dg4MDHRl27pp5cqVXblbbG9vb+nETN9/s/244kwBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBp3sN/ZKr09fWVmay/v7/tdQYHB0u3rFq1qivPM3/+/LbXWbhw4Zy7oVsnN7frRCf7bjbsv9nOmQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIb4nXBypUrp3sTaEFvb2/b6yxatKjMZN26uV0nhoaGpnsTmIAzBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoApJ6maZrSgp6enlYWY5pvotetG6ANDw+3vc6SJUs6eq5Vq1aVmbrPFy5cWGayTl5TJ/8NdfK9dUO87mvlcO9MAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASO6SOsd0cufJV77ylWUmGxgYaHudk046qcw13brj6fLly9tep6+vr+116D53SQWgLaIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJDcEI+Obpr2hS98oe11ent7y0zW39/f9jqDg4NduWlhpzcuHB4ebnudRYsWtb0Os4Mb4gHQFlEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEhuiMeMvvFeuP7667v2XN244VynNwZcvnx52+v09fV19FzMTW6IB0BbRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAILkhHnPSsmXL2l5nYGCgzGSd3EhvxYoVU7ItzE5uiAdAW0QBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACC5IR7MkpvoDQ8Pt73OokWLpmRbmJ3cEA+AtogCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQDSvIf/CMxkvb29ba/T19fX9jpDQ0Ntr8Pc4UwBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgCpp2maprSgp6enlcVg1rrhhhu6cpO6gYGB0on+/v7SDX7W565WDvfOFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkNwQD/5fiz8KYwwPD7e9zqJFi0q3tq8TftbnLjfEA6AtogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkOY9/EegXatXr57uTYBJ5UwBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgDJDfGYk5797Gd35XmGh4e78jzQLc4UAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGA5C6pzEkLFy4sM9WyZcumexNgrZwpAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAguSEePAIDAwNlJluyZMl0bwKzjDMFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkN8RjTlq5cmWZazq5+d7Q0NCUbAtzlzMFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgCknqZpmtKCnp6eVhaDR9VN9BYsWND2Ov39/aUTg4ODHa0HI1o53DtTACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkrukAjxKNO6SCkA7RAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQ5pUWNU3T6qIAzFLOFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFAAoI/4PjIhhEBPKzQ0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test on a few training examples\n",
    "for i in range(4):\n",
    "    test_prediction(i, nn, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a701b365",
   "metadata": {},
   "source": [
    "### 8. Evaluating on the Dev Set\n",
    "\n",
    "After training and testing on individual examples, we evaluate the model's performance on the dev set.\n",
    "\n",
    "- The dev set contains unseen data to test generalization.\n",
    "- We use the same forward propagation and prediction logic to get outputs.\n",
    "- Accuracy is calculated by comparing predicted labels with actual labels.\n",
    "\n",
    "This gives us an unbiased estimate of how well the model will perform on new, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ade492fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev Set Accuracy: 0.8548548548548549\n"
     ]
    }
   ],
   "source": [
    "dev_predictions = make_predictions(nn,X_dev)\n",
    "print(\"Dev Set Accuracy:\", nn.accuracy(dev_predictions, Y_dev))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
